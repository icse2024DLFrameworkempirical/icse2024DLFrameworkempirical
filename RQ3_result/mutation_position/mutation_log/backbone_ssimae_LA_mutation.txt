Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
1 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.9 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=64, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(64,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
2 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.6 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
3 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.1 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 128, 128] out_shape: [2, 32, 128, 128]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
4 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.13 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 128, 8, 8] out_shape: [2, 128, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=8, output_channels=8>
insert_layer_outshape equal!
mut_result:True
5 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 128, 128] out_shape: [2, 32, 128, 128]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=128, output_channels=128>
insert_layer_outshape equal!
mut_result:True
6 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.3 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 64, 64] out_shape: [2, 32, 64, 64]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
7 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.7 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
8 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
9 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.7 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=32, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(32,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
10 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.5 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
11 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=64, output_channels=64, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
12 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: encoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 128, 128] out_shape: [2, 32, 128, 128]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
13 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.6 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
14 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.6 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=32, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(32,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
15 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: encoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 128, 128] out_shape: [2, 32, 128, 128]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=128, output_channels=128, has_bias=True>
insert_layer_outshape equal!
mut_result:True
16 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: encoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 128, 128] out_shape: [2, 32, 128, 128]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
17 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.13 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 8, 8] out_shape: [2, 128, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
18 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.17 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=32, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(32,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
19 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
20 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.5 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
21 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.11 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
22 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.6 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
23 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: encoded.13 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 8, 8] out_shape: [2, 128, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
24 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.13 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 8, 8] out_shape: [2, 128, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
25 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:2
select layer: encoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 128, 128] out_shape: [2, 32, 128, 128]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
26 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.9 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=64, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(64,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
27 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.9 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=64, output_channels=64, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
28 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.3 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 64, 64] out_shape: [2, 32, 64, 64]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
29 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.9 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
30 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=64, output_channels=64, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
31 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.17 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=8, output_channels=8, has_bias=True>
insert_layer_outshape equal!
mut_result:True
32 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=64, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(64,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
33 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
34 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: encoded.7 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 32, 32] out_shape: [2, 32, 32, 32]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=32, output_channels=32, has_bias=True>
insert_layer_outshape equal!
mut_result:True
35 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.17 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
36 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.3 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 64, 64] out_shape: [2, 32, 64, 64]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=32, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(32,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
37 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.10 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=64, output_channels=64, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
38 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.11 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 16, 16] out_shape: [2, 64, 16, 16]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
39 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: encoded.15 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 8, 8] out_shape: [2, 64, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=64, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(64,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
40 generation!

