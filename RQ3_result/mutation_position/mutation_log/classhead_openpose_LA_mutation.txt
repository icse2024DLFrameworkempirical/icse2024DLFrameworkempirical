Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
1 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv2_CPM_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
2 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv3_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
3 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv2_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
4 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
5 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv3_CPM_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
6 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv3_CPM_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
7 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv3_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
8 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv2_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
9 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.relu layer_type: <class 'mindspore.nn.layer.activation.ReLU'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
10 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
11 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv2_CPM_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
12 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv3_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
13 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv5_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
14 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv2_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
15 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv5_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
16 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
17 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv4_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
18 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
19 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv6_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
20 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv6_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
21 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.relu layer_type: <class 'mindspore.nn.layer.activation.ReLU'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
22 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv3_CPM_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
23 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv3_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
24 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv4_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
25 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv4_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
26 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv5_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
27 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv2_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
28 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv3_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
29 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv5_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
30 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv5_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
31 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
32 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv4_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
33 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: stage_5.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
34 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.relu layer_type: <class 'mindspore.nn.layer.activation.ReLU'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
35 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
36 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv5_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
37 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv2_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
38 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv6_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
39 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv3_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
40 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: stage_5.conv2_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
41 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv3_CPM_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
42 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
43 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: stage_2.conv5_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
44 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
45 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv1_CPM_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
46 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv3_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
47 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.relu layer_type: <class 'mindspore.nn.layer.activation.ReLU'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
48 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv4_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
49 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv2_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
50 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv5_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
51 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv3_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
52 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.relu layer_type: <class 'mindspore.nn.layer.activation.ReLU'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
53 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: stage_6.conv4_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
54 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv6_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
55 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv2_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
56 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv5_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
57 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
58 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
59 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv4_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
60 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv5_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
61 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
62 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: stage_6.conv2_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
63 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv6_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
64 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv2_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
65 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv5_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
66 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv5_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
67 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.relu layer_type: <class 'mindspore.nn.layer.activation.ReLU'> in_shape: [2, 512, 46, 46] out_shape: [2, 512, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=512, output_channels=512, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:False
68 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: stage_5.conv6_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
69 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv3_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
70 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
71 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv6_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
72 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv4_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
73 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: stage_2.conv2_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
74 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv4_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
75 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv3_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
76 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv3_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
77 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv3_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
78 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
79 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
80 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: stage_5.conv2_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
81 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.relu layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
82 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: stage_4.relu layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
83 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv3_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
84 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv5_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
85 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_6.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
86 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
87 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv4_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
88 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: stage_3.conv3_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
89 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: stage_5.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=128, output_channels=128, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
90 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv2_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
91 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
92 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_3.conv4_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46, has_bias=True>
insert_layer_outshape equal!
mut_result:True
93 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv6_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
94 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_2.conv5_L2 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
95 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv6_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
96 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: stage_3.conv5_L1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
97 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_4.conv2_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=128, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(128,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
98 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_5.conv3_L2 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
99 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: stage_1.conv1_CPM_L1 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 128, 46, 46] out_shape: [2, 128, 46, 46]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=46, output_channels=46>
insert_layer_outshape equal!
mut_result:True
100 generation!

