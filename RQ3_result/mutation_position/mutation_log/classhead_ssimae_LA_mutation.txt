Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.7 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
1 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.9 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
2 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.13 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 38, 38] out_shape: [2, 32, 38, 38]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=38, output_channels=38>
insert_layer_outshape equal!
mut_result:True
3 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: decoded.13 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 38, 38] out_shape: [2, 32, 38, 38]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
4 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.17 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 158, 158] out_shape: [2, 32, 158, 158]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
5 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.8 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
6 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.3 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 8, 8] out_shape: [2, 64, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
7 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.5 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 128, 8, 8] out_shape: [2, 128, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=8, output_channels=8, has_bias=True>
insert_layer_outshape equal!
mut_result:True
8 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.7 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
9 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.17 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 158, 158] out_shape: [2, 32, 158, 158]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=32, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(32,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
10 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.17 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 158, 158] out_shape: [2, 32, 158, 158]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=158, output_channels=158>
insert_layer_outshape equal!
mut_result:True
11 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.8 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=18, output_channels=18>
insert_layer_outshape equal!
mut_result:True
12 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.15 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 78, 78] out_shape: [2, 32, 78, 78]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
13 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.3 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 8, 8] out_shape: [2, 64, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
14 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.1 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
15 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: decoded.8 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=64, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(64,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
16 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.9 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
17 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.1 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=8, output_channels=8>
insert_layer_outshape equal!
mut_result:True
18 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.9 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
19 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.17 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 158, 158] out_shape: [2, 32, 158, 158]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
20 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.9 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=64, output_channels=64, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
21 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.7 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
22 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.11 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 38, 38] out_shape: [2, 32, 38, 38]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
23 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.13 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 38, 38] out_shape: [2, 32, 38, 38]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
24 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.11 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 32, 38, 38] out_shape: [2, 32, 38, 38]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
25 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.19 layer_type: <class 'mindspore.nn.layer.activation.Sigmoid'> in_shape: [2, 3, 316, 316] out_shape: [2, 3, 316, 316]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=316, output_channels=316, has_bias=True>
insert_layer_outshape equal!
mut_result:True
26 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
27 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.15 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 78, 78] out_shape: [2, 32, 78, 78]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=78, output_channels=78>
insert_layer_outshape equal!
mut_result:True
28 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.3 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 8, 8] out_shape: [2, 64, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
29 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
30 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.19 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 3, 316, 316] out_shape: [2, 3, 316, 316]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For Maxpool3DWithArgmax, pads should be less equal to the half of ksize, but got ksize is[[const vector]{1, 1, 1}], pads is[[const vector]{0, 1, 1}].

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/max_pool3d_with_argmax.cc:173 CheckKsizeAndPads

mut_result:LA Create illegal layer!
31 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.19 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 3, 316, 316] out_shape: [2, 3, 316, 316]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=3, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(3,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(3,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(3,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(3,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
32 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: decoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=32, output_channels=32, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
33 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:0
select layer: decoded.15 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 78, 78] out_shape: [2, 32, 78, 78]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=78, output_channels=78>
insert_layer_outshape equal!
mut_result:True
34 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.7 layer_type: <class 'mindspore.nn.layer.activation.LeakyReLU'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Conv2d<input_channels=64, output_channels=64, kernel_size=(1, 1), stride=(1, 1), pad_mode=valid, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=[[[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 ...


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]


 [[[1.]]

  [[1.]]

  [[1.]]

  ...

  [[1.]]

  [[1.]]

  [[1.]]]], bias_init=[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.], format=NCHW>
insert_layer_outshape equal!
mut_result:True
35 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.8 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=64, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(64,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
36 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.12 layer_type: <class 'mindspore.nn.layer.conv.Conv2d'> in_shape: [2, 32, 38, 38] out_shape: [2, 32, 38, 38]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: BatchNorm2d<num_features=32, eps=1e-05, momentum=0.5, gamma=Parameter (name=gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=variance, shape=(32,), dtype=Float32, requires_grad=False)>
insert_layer_outshape equal!
mut_result:True
37 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:2
select layer: decoded.15 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 78, 78] out_shape: [2, 32, 78, 78]
mut Basic type: True
add Basic layer : Basic_op
Illegal LA mutate!
For 'AvgPool3D the sum of the pads in the two directions should be less than or equal to the corresponding kernel size, but got pads: (0,0,2,2,2,2) and kernel: (1, 1, 1)

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/core/ops/avg_pool_3d.cc:162 GetPadsByPadding

mut_result:LA Create illegal layer!
38 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:-1
select layer: decoded.1 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 32, 8, 8] out_shape: [2, 32, 8, 8]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=8, output_channels=8, has_bias=True>
insert_layer_outshape equal!
mut_result:True
39 generation!

Adopt LA mut_strategy!
candidate_in_mutlayers_indice:1
select layer: decoded.9 layer_type: <class 'mindspore.nn.layer.container.SequentialCell'> in_shape: [2, 64, 18, 18] out_shape: [2, 64, 18, 18]
mut Basic type: True
add Basic layer : Basic_op
select insert layer: Dense<input_channels=18, output_channels=18, has_bias=True>
insert_layer_outshape equal!
mut_result:True
40 generation!

